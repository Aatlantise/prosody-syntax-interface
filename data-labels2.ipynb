{
 "cells": [
  {
   "cell_type": "code",
   "id": "8a858ee0-53d8-47fc-bb6e-d287593a5417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:08:35.659260Z",
     "start_time": "2025-03-30T20:08:35.653856Z"
    }
   },
   "source": [
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4a0c182-e09d-44ae-a3ed-a739031e7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dir = \"/home/jm3743/data/LibriTTSLabelNP/lab/word/\"\n",
    "text_dir = \"/home/jm3743/data/LibriTTSNP/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae0f0cc9-6291-4475-98b4-3610ad5c21df",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = \"dev-clean/1272/128104/1272_128104_000001_000000\"\n",
    "text_file = text_dir + iterator + \".normalized.txt\"\n",
    "word_file = word_dir + iterator + \".lab\"\n",
    "\n",
    "text = open(text_file).read()\n",
    "word = open(word_file).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e815ad15-5a18-4ecb-bf2b-a91b68743811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NP> A 'JOLLY' ART CRITIC </NP>\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8d668b6-abb2-43c9-8fcb-26ca4a36275e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0\\t0.03\\t',\n",
       " '0.03\\t0.13\\ta',\n",
       " '0.13\\t0.6\\tjolly',\n",
       " '0.6\\t0.63\\t',\n",
       " '0.63\\t0.83\\tart',\n",
       " '0.83\\t0.86\\t',\n",
       " '0.86\\t1.38\\tcritic',\n",
       " '1.38\\t1.52\\t',\n",
       " '']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "id": "a51450c0-a52e-417e-a046-9d869b0503d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:09:14.444399Z",
     "start_time": "2025-03-30T20:09:14.436692Z"
    }
   },
   "source": [
    "import pdb\n",
    "def add_tokens(running_text, sample_line_input):\n",
    "    running_tokens = running_text.split(\" \")\n",
    "    lines_with_tags = []\n",
    "    lines = sample_line_input.split('\\n')\n",
    "\n",
    "    n_lines = len(lines)\n",
    "    n_special_tags = 0\n",
    "    n_blanks = 0\n",
    "    n_words = 0\n",
    "\n",
    "    line = 0\n",
    "    for token in running_tokens:\n",
    "        if token in [\"<NP>\", \"<VP>\"]:\n",
    "            n_special_tags += 1\n",
    "            # pdb.set_trace()\n",
    "\n",
    "            # iterate until we see the first word of the NP as there may be empty duration lines\n",
    "            while line < len(lines) and lines[line].split('\\t')[-1] == \"\":\n",
    "                n_blanks += 1\n",
    "                # pdb.set_trace()\n",
    "                # print(lines[line])\n",
    "                lines_with_tags.append(lines[line])\n",
    "                line += 1\n",
    "\n",
    "            # pdb.set_trace()\n",
    "            b, e, word = lines[line].split(\"\\t\")\n",
    "            # print(\"\\t\".join([b, b, token]))\n",
    "            lines_with_tags.append(\"\\t\".join([b, b, token]))\n",
    "\n",
    "            \n",
    "        elif token in [\"</NP>\", \"</VP>\"]:\n",
    "            n_special_tags += 1\n",
    "            # pdb.set_trace()\n",
    "            # print(\"\\t\".join([e, e, token]))\n",
    "            lines_with_tags.append(\"\\t\".join([e, e, token]))\n",
    "            \n",
    "        else:\n",
    "            # pdb.set_trace()\n",
    "            while line < len(lines) and lines[line].split('\\t')[-1] == \"\":\n",
    "                n_blanks += 1\n",
    "                # pdb.set_trace()\n",
    "                # print(lines[line])\n",
    "                lines_with_tags.append(lines[line])\n",
    "                line += 1\n",
    "            \n",
    "            n_words += 1\n",
    "            b, e, word = lines[line].split(\"\\t\")\n",
    "\n",
    "            # print(lines[line])\n",
    "            lines_with_tags.append(lines[line])\n",
    "            line += 1\n",
    "    for l in lines[line:]:\n",
    "        # print(l)\n",
    "        lines_with_tags.append(l)\n",
    "        if l.split('\\t')[-1] == \"\":\n",
    "            n_blanks += 1\n",
    "    return \"\\n\".join(lines_with_tags), n_words + n_blanks == n_lines, \n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e5d542c4-cc6b-405a-82c6-24a9bee71578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:14:23.355430Z",
     "start_time": "2025-03-30T20:10:40.083497Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "word_read_dir = \"/home/jm3743/data/LibriTTSLabel/lab/word/\"\n",
    "word_write_dir = \"/home/jm3743/data/LibriTTSLabelNPVP/lab/word/\"\n",
    "text_dir = \"/home/jm3743/data/LibriTTSNPVP/\"\n",
    "\n",
    "good = 0\n",
    "bad = 0\n",
    "\n",
    "for split in [\n",
    "    'dev-clean',\n",
    "              'test-clean',\n",
    "              # 'train-clean-100'\n",
    "             ]:\n",
    "    for book in tqdm(os.listdir(os.path.join(word_read_dir, split))):\n",
    "        for chapter in os.listdir(os.path.join(word_read_dir, split, book)):\n",
    "            for sent in os.listdir(os.path.join(word_read_dir, split, book, chapter)):\n",
    "\n",
    "                word = open(os.path.join(word_read_dir, split, book, chapter, sent)).read()\n",
    "                text = open(os.path.join(text_dir, split, book, chapter, sent)[:-4] + \".normalized.txt\").read()\n",
    "                try:\n",
    "                    lines_with_tags, checker = add_tokens(text, word)\n",
    "                    if checker:\n",
    "                        good += 1\n",
    "                        with open(os.path.join(word_write_dir, split, book, chapter, sent), \"w\") as f:\n",
    "                            f.write(lines_with_tags)\n",
    "                    else:\n",
    "                        bad += 1\n",
    "                except:\n",
    "                    bad += 1\n",
    "\n",
    "\n",
    "print(good)\n",
    "print(bad)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:58<00:00,  2.97s/it]\n",
      "100%|██████████| 39/39 [01:44<00:00,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9844\n",
      "708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6179b53c-784f-4076-a881-0ae6a711765b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\t0.03\t\n",
      "0.03\t0.03\t<NP>\n",
      "0.03\t0.13\ta\n",
      "0.13\t0.6\tjolly\n",
      "0.6\t0.63\t\n",
      "0.63\t0.83\tart\n",
      "0.83\t0.86\t\n",
      "0.86\t1.38\tcritic\n",
      "1.38\t1.38\t</NP>\n",
      "1.38\t1.52\t\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "lines_with_tags, checker = add_tokens(text, word)\n",
    "print(lines_with_tags)\n",
    "print(n_words, n_lines, n_blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3feb682d-ae46-4630-a3f3-f420aabee8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1291, 0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d51118-8f76-424f-a3f4-c681895e145f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
