import argparse
from pathlib import Path
from datasets import Dataset
from transformers import (
    T5Config, Seq2SeqTrainer, Seq2SeqTrainingArguments,
    PreTrainedTokenizerBase, EarlyStoppingCallback, T5ForConditionalGeneration
)
from constituency.util import TokenizerBuilder, load_jsonl_data, preprocess
from constituency.model import DualEncoderT5, DualEncoderCollator
from sklearn.model_selection import KFold


def get_tokenizer():
    builder = TokenizerBuilder("t5-base")
    tokenizer = builder.build_tokenizer()
    return tokenizer

def single_run(args, tokenizer, tokenized_train, tokenized_eval):
    outdir = Path(args.outdir)
    outdir.mkdir(parents=True, exist_ok=True)

    print("Initializing DualEncoder model...")
    # Load base model + config first
    base = T5ForConditionalGeneration.from_pretrained(args.model_name)

    # Resize embeddings to new tokenizer
    base.resize_token_embeddings(len(tokenizer))

    # Update config so new model matches
    config = base.config
    config.vocab_size = len(tokenizer)

    # Now build your custom model
    model = DualEncoderT5(config)
    model.tokenizer = tokenizer

    # Load pretrained weights to only the encoder and shared (to be used as encoder embedding layer)
    print("Loading  weights...")
    missing, unexpected = model.load_state_dict(base.state_dict(), strict=False)

    print("Missing keys:", missing)
    print("Unexpected keys:", unexpected)

    print("Re-initializing decoder layer, to be trained from scratch")
    model.decoder.init_weights()

    model.to(args.device)

    collator = DualEncoderCollator(tokenizer,
                                   device=args.device,
                                   return_text=args.use_text,
                                   return_pause=args.use_pause,
                                   return_duration=args.use_duration,
                                   return_zeros=args.use_zeros)

    training_args = Seq2SeqTrainingArguments(
        output_dir=str(outdir / "model"),
        per_device_train_batch_size=args.batch_size,
        per_device_eval_batch_size=args.batch_size,
        learning_rate=args.lr,
        num_train_epochs=args.epochs,
        logging_steps=args.logging_steps,
        eval_steps=args.eval_steps,
        save_steps=args.save_steps,
        save_total_limit=1,
        weight_decay=0.01,
        fp16=args.fp16,
        remove_unused_columns=False,
        eval_strategy="steps" if args.eval_steps > 0 else "no",
        metric_for_best_model="eval_loss",
        greater_is_better=False,
        predict_with_generate=False,
        report_to=["tensorboard"],
        load_best_model_at_end = True
    )

    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        tokenizer=tokenizer,
        data_collator=collator,
        train_dataset=tokenized_train,
        eval_dataset=tokenized_eval,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
    )
    trainer.model.floating_point_ops = lambda _: 0  # allow input_ids = None

    print("Training...")
    trainer.train()
    trainer.save_model(str(outdir / "model_final"))

    print("Evaluating...")
    eval_res = trainer.evaluate()
    print("Eval loss (nats/token):", eval_res["eval_loss"])

    return eval_res

def main(args):
    k = 5
    kf = KFold(n_splits=k, shuffle=True, random_state=42)

    print("Loading data...")
    items = load_jsonl_data(args.data, debug=args.debug)
    print(f"Loaded {len(items)} examples.")

    # Convert the list of items to a Hugging Face Dataset
    ds_full = Dataset.from_list(items)
    full_indices = list(range(len(ds_full)))  # Get the indices of the full dataset

    # --- Cross-Validation Loop ---
    # This loop will run K times, once for each fold

    all_fold_metrics = []
    for fold, (train_index, eval_index) in enumerate(kf.split(full_indices)):
        print(f"\n--- Starting Fold {fold + 1}/{k} ---")

        # 1. Create Train and Evaluation Datasets for the current fold
        # Use the indices generated by KFold to select the data slices
        train_ds = ds_full.select(train_index)
        eval_ds = ds_full.select(eval_index)

        print(f"Fold {fold + 1} sizes: Train={len(train_ds)}, Eval={len(eval_ds)}")

        # 2. Preprocessing (as you had it)
        print("Loading tokenizer...")
        # NOTE: You might move get_tokenizer() outside the loop if it's slow,
        # but I'm keeping the original structure for clarity.
        tokenizer = get_tokenizer()

        print("Preprocessing...")
        preprocess_fn = lambda ex: preprocess(tokenizer, ex, args.max_source_length, args.max_target_length)

        # Map the preprocessing function onto the current fold's datasets
        tokenized_train = train_ds.map(preprocess_fn, batched=True, remove_columns=train_ds.column_names)
        tokenized_eval = eval_ds.map(preprocess_fn, batched=True, remove_columns=eval_ds.column_names)

        per_seq_len = sum([len([t for t in ex if t != -100]) for ex in tokenized_eval['labels']]) / len(tokenized_eval['labels'])
        print(f"Token length per parse sequence: {per_seq_len:.4f}")

        # 3. Model Training and Evaluation (Your next steps)
        # --- YOUR TRAINING/EVALUATION CODE GOES HERE ---
        fold_res = single_run(args, tokenizer, tokenized_train, tokenized_eval)
        fold_eval_loss = fold_res['eval_loss']

        print(f"Fold {fold + 1} Evaluation per token: {fold_eval_loss:.4f}")
        print(f"Fold {fold + 1} Entropy per sequence: {fold_eval_loss * per_seq_len:.4f}")

        all_fold_metrics.append(fold_eval_loss * per_seq_len)

    # --- Final Results ---
    import numpy as np
    final_mean = np.mean(all_fold_metrics)
    final_std = np.std(all_fold_metrics)

    print("\n--- Cross-Validation Results ---")
    print(f"Individual Fold Metrics: {all_fold_metrics}")
    print(f"Mean Metric (Entropy/Loss): {final_mean:.4f}")
    print(f"Standard Deviation (Variance Measure): {final_std:.4f}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data", type=str, default="/home/jm3743/prosody-syntax-interface/data/constituency_corpus.json")
    parser.add_argument("--model_name", type=str, default="t5-base")
    parser.add_argument("--max_source_length", type=int, default=256)
    parser.add_argument("--max_target_length", type=int, default=256)
    parser.add_argument("--batch_size", type=int, default=16)
    parser.add_argument("--lr", type=float, default=5e-5)
    parser.add_argument("--epochs", type=int, default=30)
    parser.add_argument("--validation_split", type=float, default=0.1)
    parser.add_argument("--eval_steps", type=int, default=500)
    parser.add_argument("--logging_steps", type=int, default=500)
    parser.add_argument("--save_steps", type=int, default=500)
    parser.add_argument("--fp16", action="store_true")
    parser.add_argument("--device", type=str, default="cuda")
    parser.add_argument("--use_pause", action="store_true", default=False)
    parser.add_argument("--use_duration", action="store_true", default=False)
    parser.add_argument("--use_zeros", action="store_true", default=False)
    parser.add_argument("--use_text", action="store_true", default=False)
    parser.add_argument("--debug", action="store_true", default=False)
    args = parser.parse_args()

    feats = []
    if args.use_zeros:
        feats.append("zero")
    elif args.use_pause:
        feats.append("pause")
    elif args.use_duration:
        feats.append("duration")
    if args.use_text:
        feats.append("text")
    if args.debug:
        feats.append("debug")
    args.outdir = f"/home/jm3743/prosody-syntax-interface/outputs/{'_'.join(feats)}"

    main(args)
